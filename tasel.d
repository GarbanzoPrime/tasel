/* Copyright 2013, Garbanzo Prime

    This file is part of tasel.
    tasel is subject to the license specified in LICENSE.txt
*/
 
module tasel.tasel ;

import std.concurrency ;
import std.parallelism ;
import std.stdio ;
import std.process ;
import std.exception ;
import std.file ;
import std.path ;
import std.datetime ;
import std.algorithm ;
import std.array ;
import std.range;
import std.typecons;
import tasel.serialize ;

struct Resource {

	this( string in_name , string in_type ) {
		name = in_name ;
		type = in_type ;
	}

	string name ;
	string type ;

	const hash_t toHash(){
		hash_t hash; 
		foreach (char c; name) hash = (hash * 9) + c; 
		return hash;
	} 
	const bool opEquals(ref const Resource s){
		return std.string.cmp(this.name, s.name) == 0;
	}

	const int opCmp(ref const Resource s){
		return std.string.cmp(this.name, s.name);
	}

}

Resource FileRes( string file_name ) {
	return Resource( file_name , "file" ) ; 	
}

Resource AliasRes( string alias_name ) {
	return Resource( alias_name , "alias" ) ; 	
}

alias string TaskId ;



/** 
A utility function to create a batch of tasks
  
It functions in a way similar to std.alogorithm.map()

Example:
----
Builder env = new builder() ;

immutable string[] src =  [
  "file1.txt" ,
  "file2.txt" ,
  "file3.txt"
] ;

env.makeTasks!( e => new CopyFile( e , "bin/" ~ e ) ) ( src ) ) ; 

----

Params:
  fun = The function to apply
  env = The environment in which to add the tasks
  r   = A range 
Returns:
  An immutable array containing the tasks that wre just created
*/
template makeTasks( fun...) {
	auto makeTasks( Range )( Range r ) {
		auto result = assumeUnique( array( map!( fun )(r ) ) ) ;
		return result ;
	}
}

/**
Users can override this class to create custom build task types.

The task's constructor should fill two member variables:
$(UL
	$(LI inputs: the list of explicit resources needed by the task. Any resource requiring extra processing to determine should
	             be discovered through getImplicitInputs() instead )
	$(LI outputs: The exhaustive list of resources generated by the task)
)
*/
class UserTask : BaseTask {

	this( Resource input , Resource output ) {
		inputs = [input] ;
		outputs = [output] ;
	}

	this( Resource input , Resource[] output ) {
		inputs = [input] ;
		outputs = output ;
	}

	this( Resource[] input , Resource output ) {
		inputs = input ;
		outputs = [output] ;
	}

	this( Resource[] input , Resource[] output ) {
		inputs = input ;
		outputs = output ;
	}
	
	/**
	(Mandatory) Override this function with whatever the build task should accomplish
	*/
	bool run() immutable { return true ; }

	/**
	(Optional) Override this function if the task has a mechanism to discover additional dependencies beyond the contents of input
	*/
	override immutable( Resource )[] getImplicitInputs() immutable { return [] ; }


	override final bool _run( Tid main_thread ) immutable {
		return run() ;
	}
}

/**
	Holds a set of Tasks. 
	Tasks must be immutable before they can be stored in a BuildSet.

	Adding tasks to a buildSet is simply a matter of using the ~= operator.
*/
class BuildSet {
	void opOpAssign(string op : "~", Range)(Range items) if( isInputRange!(Range))
    {
    	foreach( task ; items )
    	{
    		_addTask( task );
    	}
    }

	void opOpAssign(string op : "~")(immutable(BaseTask) item)
    {
        _addTask( item );
    }    

private:
	void _addTask( immutable( BaseTask ) new_task ) {
		foreach( res ; new_task.outputs ) {
			auto existing = res in _depMap ;
			if( existing ) {
				auto incoming_id = new_task.getId() ;
				auto present_id = (*existing).getId() ;

				if( incoming_id != present_id) {
					new Exception(res.name ~ " is generated by 2 tasks with different ids : \n\t" ~ incoming_id ~ "\nand\n\t" ~ present_id );
				}
			}
			else {
				_depMap[ res ] = new_task ;
			}
		}
	}

	immutable( BaseTask )[ Resource ] _depMap ;
}



/**
	Builds a set of resources, using the provided tasks, and using an optional previous history to optimize. The function will return
	once the build is complete.

	Params:
	  resource: the list of resources to build
	  tasks: a set of tasks to potentially run
	  workers_count: The number of allowed tasks running in parallel
	  in_old_history: The result of a previous build request, which can be used to optimize the build.
	
	Returns:
	  A BuildHistory containing a history of what happened during the build. 
*/
BuildHistory build( Resource[] resources , BuildSet tasks  , int workers_count , BuildHistory in_old_history ) {
	BuildRunner runner = BuildRunner( tasks , workers_count ) ;
	
	runner.build( resources , in_old_history ) ;
	return runner.history ;
}

/**
	Builds a single resource 
*/
BuildHistory build( Resource resource  , BuildSet tasks , int workers_count , BuildHistory in_old_history) {
	return build( [ resource ]  , tasks , workers_count , in_old_history ) ;
}

/**
	Represents the results of a build request.
*/
class BuildHistory {
	/**
		Loads the history from a binary data stream. Most likely a File, but anything supported by the byChunk() Range will work. It is assumed
		that the data was generated by BuildHistory.writeTo() in the first place. 
	*/
	void readFrom(T)( T from_file ) {
		taskHistories = from_file.byChunk( 4096 ).joiner().deserialize!(TaskHistory[TaskId])() ;
	}

	/**
		Writes the history to the passed binary data stream. Most likely a File, but anything implemented rawWrite will work.
	*/
	void writeTo(T)( T to_file ) {
		foreach( data ; taskHistories.serialize() ) {
			to_file.rawWrite( data ) ;
		}
	}

	
private:
	TaskHistory[TaskId] taskHistories ;
}

private:

struct BuildRunner {
	this( BuildSet tasks , int workers_count ) {
		_depMap = tasks._depMap ;
		_workers = new TaskPool( workers_count ) ; 
	}

	~this() {
		_workers.stop() ;
	}


	void build( Resource[] resources , BuildHistory in_old_history ) {
		history = in_old_history ;

		timer = 0 ;
		
		
		auto main_ts = new TaskState( new RootTask() ) ;
		_workMap[ main_ts.task.getId() ] = main_ts ;

		foreach( res ; resources ) {

			auto root_ts = _buildResource( res ) ;
			if( root_ts && root_ts.status != TaskState.Status.Done ) {
				root_ts.dependants ~= main_ts ;
				main_ts.depends_on++;
			}
		}

		if( main_ts.depends_on > 0 ) {
			bool done = false ;
			while( !done ) {
				// event handling loop
				receive( 
					( RootTask.RootTaskDone e ) { done = true ; } ,
					( DepPassResult e ) { _depPassComplete( e ) ; } ,
					( BuildResult e ) { _buildComplete( e ) ; },
					( Variant e ) { writeln( "error") ; }
				) ;
			}
		}
	}

	

private:

	TaskState _prepareResource( Resource res ) {

		auto matching_task_ptr = res in _depMap ;
		if( !matching_task_ptr ) {
			return null ;
		}

		auto matching_task = *matching_task_ptr ;

		auto task_id = matching_task.getId() ;

		if( task_id in _workMap ) {
			//we are working on this one already
			return _workMap[ task_id ] ; 
		}

		auto new_ts = new TaskState( matching_task ) ;
		_workMap[ task_id ] = new_ts ;

		//we need to establish immediately if this will be a skipped task or not
		bool needs_rebuild = true ;
		if( task_id in history.taskHistories ) {
			auto tsk_hist = history.taskHistories[task_id] ;
			if( tsk_hist.buildSucceeded )
			{
				needs_rebuild = false ;
				//this is a task that was completed successfully (last time we checked)

				
				foreach( old_generated ; tsk_hist.gereatedFiles ) {
					try {
						if( timeLastModified( old_generated.resource.name ) > SysTime( old_generated.timestamp ) ) {
							needs_rebuild = true ;
									break ;
						}
					}
					catch( FileException e ) {
						needs_rebuild = true ;
						break ;
					}
				}

				//if none of the dependencies have been touched, then we shoudn't bother with any other pass
				//should we do this as a pass? I don't think so...		
				if( !needs_rebuild ) {
					foreach( old_dep ; tsk_hist.discoveredDependencies ) {
						auto old_dep_ts = _prepareResource( old_dep.resource ) ;
						if( old_dep_ts ) {
							if( old_dep_ts.wasSkipped != true ) {
								needs_rebuild = true ;
								break ;
							}
						}
						else {
							try {
								if( timeLastModified( old_dep.resource.name ) > SysTime( old_dep.timestamp ) )
								{
									needs_rebuild = true ;
									break ;
								}
							}

							catch( FileException e ) {
								//the file does not exist anymore...
								needs_rebuild = true ;
								break ;
							}
						}
					}
				}
			}

			if( needs_rebuild ) {
				//if we will rebuild, strip it out of the history, it'll get re-added in due time
				history.taskHistories.remove( task_id ) ;
			}
			else {
				new_ts.wasSkipped = true ;
				new_ts.status = TaskState.Status.Done ;
			}
		}

		return new_ts ;
	}

	TaskState _buildResource( Resource res , string msg_prefix = "" ) {

		auto ts = _prepareResource( res ) ;

		if( !ts ) {
			return null ;
		}

		if( ts.status != TaskState.Status.Ready ) {
			return ts ;
		}

		writeln( msg_prefix ~ "->requesting: " ~ res.name) ;
		//launch a dependency pass once all known deps have been resolved
		foreach( dep ; ts.task.inputs ) {
			auto dep_ts = _buildResource( dep , msg_prefix ~ " |" ) ;
			if( dep_ts ) {
				if( dep_ts.status == TaskState.Status.Failed ) {
					ts.status = TaskState.Status.Failed ;
				}
				else if( dep_ts.status != TaskState.Status.Done ) {
					dep_ts.dependants ~= ts ;
					ts.depends_on++ ;
				}
			}
		}

		if( ts.depends_on == 0 && ts.status != TaskState.Status.Failed ) {
			_launchDepPass( ts ) ;
		}

		return ts ;
	}


	void _launchDepPass( TaskState target )	{
		if( target.status != TaskState.Status.Failed )
		{
			target.status = TaskState.Status.InDepPass ;
			target.launchTime = ++timer ;

			_workers.put( task!_implicitDepPass( target.task , thisTid ) ) ;
		}
	}

	void _depPassComplete( DepPassResult result ) {
		
		auto pass_ts = _workMap[ result.target ] ;
		/*
		
		The following block of code might look weird, in order to understand it, consider the following example:
			given 3 tasks:
			A) builds main.cpp
			B) builds data.hpp
			C) builds sub_data.hpp
			main.cpp includes data.hpp
			data.hpp will include sub_data.hpp once it has been generated
			
			

			if for some reason B.build is lauched while  A.dep is running, and concludes FASTER, then 
			it's possible that A.dep will have read data.hpp BEFORE it ever included sub_data.hpp, and yet have all
			the dep_ts.status set to TaskState.Status.Done. So task C would NEVER RUN!

		This should be super duper rare and only ever happen on a first build, so it's not a huge performance concern
		*/
		
		bool relaunch = false ;

		foreach( dep ; result.foundDeps ) {
			auto dep_ts = _buildResource( dep ) ;
			if( dep_ts ) {
				if( dep_ts.status == TaskState.Status.Failed )
				{//we have discovered that we depend on something that has failed
					_declareFailure( pass_ts ) ;
					return ;
				}

				if( dep_ts.status == TaskState.Status.Done ) {
					//this is extremely suspicious, the only way to be sure is to relaunch a dep pass
					if( dep_ts.completeTime > pass_ts.launchTime ) { 
						relaunch = true ;
					}
				}
				else {
					dep_ts.dependants ~= pass_ts ;
					pass_ts.depends_on++ ;
				}
			}
		}

		//if we don't depend on anyone anymore, then go and build, otherwise, we will need yet another dep pass
		if( pass_ts.depends_on == 0 ) {
			if( relaunch ) {
				//cannot 100% guarantee that things happenends in the right order
				_launchDepPass( pass_ts ) ;
			}
			else {
				//make a new history for that task
				TaskHistory new_history ;


				foreach( dep ; pass_ts.task.inputs ) {
					if( exists( dep.name ) ) {
						new_history.discoveredDependencies ~= HistoricalDependency( dep , timeLastModified( dep.name ).stdTime() ) ;
					}
					//else
					// not a file, disregard for now
				}

				foreach( dep ; result.foundDeps ) { 
					if( exists( dep.name ) ) {
						new_history.discoveredDependencies ~= HistoricalDependency( dep , timeLastModified( dep.name ).stdTime() ) ;
					}
					//else
					// not a file, disregard for now
				}

				history.taskHistories[ result.target ] = new_history ;
				_launchBuildPass( pass_ts ) ;
			}
		}
		//else
		// if we DO depend on smoe other task(s), then that task's completion will cause a brand new dep pass to occur
		// so there's nothing special to do here
	}

	void _declareFailure( TaskState target ) {
		if( target.status != TaskState.Status.Failed )
		{
			history.taskHistories.remove( target.task.getId() ) ;
			target.status = TaskState.Status.Failed ;
		
			foreach( dep_ts ; target.dependants ) {
				_declareFailure( dep_ts ) ;
				dep_ts.depends_on-- ;
			}

			target.task._failed(thisTid) ;

			target.dependants = [] ;
		}
	}

	void _declareSuccess( TaskState target ,TaskId task_id ) {
		target.status = TaskState.Status.Done ;
		
		history.taskHistories[ task_id ].buildSucceeded = true ;

		HistoricalDependency[] gens_list = [];
		foreach( gen ; target.task.outputs ) {
			try {
				if( gen.type == "file" ) {
					gens_list ~= HistoricalDependency( gen , timeLastModified( gen.name ).stdTime() ) ;
				}
			}
			catch( FileException e ) {
				writeln( gen.name ~ " was built by a successful task, but missing, declaring the task a failure" ) ;
				//resource is not a file, no biggy
				_declareFailure( target ) ;
				return ;
			}
		}

		history.taskHistories[ task_id ].gereatedFiles = gens_list ;

		foreach( dep_ts ; target.dependants ) {
			dep_ts.depends_on-- ;
			if( dep_ts.depends_on == 0 ) {
				_launchDepPass( dep_ts ) ;
			} 
		}
		target.dependants = [] ;
	}

	void _launchBuildPass( TaskState target )	{
		if( target.status != TaskState.Status.Failed ) {
			//this HAS to be done in the main thread, otherwise, bad contention issues seem to happen
			foreach( generated_file ; target.task.outputs ) {
				auto dir = dirName( generated_file.name ) ;
				if( !exists( dir ) ) {
					mkdirRecurse(  dir ) ;
				}
			}

			target.status = TaskState.Status.Building ;
			target.launchTime = ++timer ;

			_workers.put( task!_buildPass( target.task , thisTid ) ) ;
		}
	}

	void _buildComplete( BuildResult res ) {
		auto pass_ts = _workMap[ res.target ] ;

		pass_ts.completeTime = ++timer ;

		if( !res.success ) {
			_declareFailure( pass_ts ) ;
		}
		else {
			_declareSuccess( pass_ts, res.target) ;
		}
	}

	int timer = 0 ;
	immutable( BaseTask )[ Resource ] _depMap ;
	TaskState[ TaskId ] _workMap ;
	BuildHistory history ;

	TaskPool _workers ;
}



abstract class BaseTask {
	Resource[] inputs ;
	Resource[] outputs ;

	TaskId getId() immutable {
		string result = "" ;

		foreach( input ; inputs ) {
			result ~= " " ~ input.name ;
		}

		foreach( output ; outputs ) {
			result ~= " " ~ output.name ;
		}
		return result ;
	}
	abstract bool _run( Tid main_thread ) immutable ;
	void _failed( Tid main_thread ) immutable {}

	immutable( Resource )[] getImplicitInputs() immutable { return [] ; }
}


struct BuildResult {
	TaskId target ;
	bool success ;
}

struct DepPassResult {

	TaskId target ;
	Rebindable!(immutable( Resource ) [] )foundDeps ;
}

struct HistoricalDependency {
	Resource resource ; 
	long timestamp ;	//this is the time stamp of the file aw we were about to start building
}


//fun fact, a failed task simply has no history
struct TaskHistory {
	bool buildSucceeded = false ;
	HistoricalDependency[] discoveredDependencies ;
	HistoricalDependency[] gereatedFiles ;

}


class RootTask : BaseTask {
	struct RootTaskDone {
		
	}

	override TaskId getId() immutable  { return "__tasel__::RootTask" ;} 
	override bool _run( Tid main_thread ) immutable {
		main_thread.send( RootTaskDone() ) ;
		return true ;
	}

	override void _failed( Tid main_thread ) immutable {
		main_thread.send( RootTaskDone() ) ;
	}
}

class TaskState {

	enum Status {
		Ready ,
		InDepPass ,
		Building ,
		Done,
		Failed
	} 

	bool wasSkipped = false ;

	this( immutable BaseTask target ) {
		task = target ;
		status = Status.Ready ;
		depends_on = 0 ;
	}

	Status status ;
	int launchTime ; //applies for both InDepPass and Building
	
	int completeTime ; // only applies to Building

	immutable BaseTask task ; 

	TaskState[] dependants ;
	int depends_on ;
}

//this is rather silly, but these have to be public to be sent to std.parallelism
public {
	//worker tasks
	void _implicitDepPass( immutable BaseTask target , Tid main_thread_id ) {
		try {
			DepPassResult test = DepPassResult( target.getId() ,  target.getImplicitInputs() ) ;
		
			main_thread_id.send( test ) ;		
		}
		catch( Exception e )
		{
			writeln( e.toString() ) ;
			main_thread_id.send( BuildResult( target.getId() , false ) ) ;
		}
	} 

	void _buildPass( immutable BaseTask target , Tid main_thread_id ) {
		try {
			
		
			auto success = target._run( main_thread_id ) ;
			main_thread_id.send( BuildResult( target.getId() , success ) ) ;	
		}
		catch( Throwable e ) {
			writeln( e.toString() ) ;
			main_thread_id.send( BuildResult( target.getId() , false ) ) ;
		}
	}

}
